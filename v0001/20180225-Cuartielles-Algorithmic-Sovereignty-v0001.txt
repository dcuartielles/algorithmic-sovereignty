# Algorithmic Sovereignty
'''Regaining collective power over software abstractions'''

D. Cuartielles
School of Arts and Communication, K3
Malmö University
david.cuartielles@mah.se

## Extended Abstract
In contemporary digital society control is enacted through machines commanded by dynamic programmatic structures. These structures, that we call algorithms [1], are operating on data that has been deprived of a meaning [2] and therefore have become irrelevant to us whilst it made us insignificant as our singularity got diluted in matrixes of aggregated raw information flows [3] that get automatically categorized by the algorithm itself.
The definitions of many of the new terms needed to address our new ecology of devices, services, and situations are open for discussion. In particular, when talking about artificial intelligence (AI), deep learning (DL), or machine learning (ML), it is hard to find a strong definition for any of those terms in the literature [4]. Their definitions seem to suffer from the same degree of ambiguity as contemporary digital platforms what allows them to take new forms depending on the context [5]. While there seems to be no clear definition for what AI actually means, or where its limitations may lay, there is an emerging discussion around what is good and bad in using AI to mediate our — human — everyday interactions [6]. 
In this text, I will focus in revisiting contemporary discussions around AI and how this type of technology is challenging the understanding of the real value of data. I will depart from the ideas of neutrality and technological sovereignty, to later reflect whether we should (or not) consider the algorithms behind AI in the same way as the rest of the technology. This exploration will include references from academia, technology vendors, activists, as well as the business world. The aim of this essay is contributing to building a critical discourse around technology but without denying it. I will do it through suggesting a vision on how to approach the building of an AI augmented democratic society where we, both as individuals, but also as part of a collectivity, should find out (new) ways to reclaim the access to the logic that commands our actions, the algorithm. Since these programs are part of the human-machine assemblage as much as we are [7], and since they have the possibility to monitor and modify the physical world [8], we need to re-evaluate how much of our moral decisions we want to delegate on the technology [9] [10]. I will build upon technology’s state of the art, how it is being developed, but also upon critical views of technology.

### Neutrality
It has been claimed that [digital] technology is not neutral in the sense that it is made by some of us (humans) to serve our own needs. E.g. Mantelero talks about maps not being neutral, and extends it to big data [3], Feenberg sees the role of technology “as neither determining nor as neutral” [11], and Haraway mentions how the developments of the “new industrial revolution” are neither gender- nor race-neutral [12]. This extent has been proven empirically, among others, through the work of Buolamwini [13] who, as a consequence, created the Algorithmic Justice League (AJL) to fight against what she describes as algorithmic bias [14]. In her case everything started when it became clear that some devices were not able of running computer vision algorithms on subjects of color, which came to prove the point that there were no others than light-skinned subjects used for testing the algorithms.
Rouvroy presents the difference between judgement and critique when talking about AI. Judgement describes the ability of clustering data into categories. Critique, on the other hand, defines the possibility of challenging the categories to better accommodate the data. Both actions, up to the arrival of AI, were made by us — humans —; extent that has changed now. AI is a system that never stops, where error doesn’t exist, where events have been washed away, and where categories are defined automatically by DL algorithms under parameters not understandable by us [2]. This makes impossible for us to challenge those categories, what excludes us from the possibility of making any critique that is not against the machine itself. In this case, neutrality is not just excluding one type of human — as portrayed at the beginning of this section — , but the human race per se. This is a new type of neutrality where we are all equal to the machine, but not equal with the machine, and this is the concept to challenge through algorithmic sovereignty.

### Technological sovereignty
Computers do not affect all of us in the same way, since not each one of us has the same level of access to or involvement with the technology. Typically we talk about two different components in computing machinery: the hardware (the atoms, what is mechanical, visible and can be touched), and the software (the bits, what is of a purely electrical nature, invisible to the eye). In the case that sparked Buolamwini’s AJL it was software what manifested the issue. In some other cases, it is hardware the one to blame. Since this text is focusing in the aspects behind algorithms, which are expressed in software, I will not explore the route of hardware in depth.
However, technological sovereignty is a term that has been used multiple times in the literature. It is understood differently depending on the context. Activists look at it from the perspective of building a distributed technologies and protocols for action [15]. Nations consider it relevant as a way not to depend on others, not to display weaknesses towards international forae, and to have a stronger protection against international surveillance [16]. In Latin American’s political discourse, this concept shows when e.g. talking about the ability of a nation to be independent from others which might be interfering [17] initiatives that have been tried out empirically and documented among others for the case of Venezuela and its turn towards open source software [18]. 
The one thing at which technology activists and NATO analysts seem to coincide at is that AI will require a different strategy than the one followed by previous experiences in technology sovereignty. The approach is different for each one of those actors, though. The latter (NATO analysts) suggest that better encryption is the solution to avoid surveillance, since contemporary national-scale initiatives like the German attempt to create a national email system, have a hard time competing against the technology that can be created by international corporations [16]. The earlier think that in order to ensure a better tomorrow, we will need to construct AI capable of becoming a proxy to our digital lives (see Cadon’s essay “Code is political, algorithms are weapons of math destruction”, page 33 [15]). Cadon is the first reference I have found to the term of algorithmic sovereignty, but he introduces it almost as a critique by categorizing it of futurotopia. As I will discuss later, I think the idea of using open source technology and publicly hosted AI agents governed under a new non-existing regulation for this type of systems, is a lot more sound as a possible future, considering contemporary state of affairs at socio-economical level.

### The real power of contemporary AI
We — humans — are actively experimenting in sharing our power to decide with algorithms, becoming more and more both their trainers, their subjects of study, their benefactors, and even their mentors (of the machines). In the same way we are delegating on machines for the making of moral decisions [9], we are even sometimes delegating in the creation of the mechanisms of making those moral decisions. There are examples of AI learning from us and become able of creating its own machines. Though there are still some limitations like e.g., as of the time of writing, hardware is planned and created by humans, with the exception of the process of tracing the electric paths between the different electronic components that is given to software in a process called auto-routing. As a matter of fact there are CAD programs that can make recommendations on where to place the electronic components based on experience, but it is still a human decision to both determine the final composition of a certain design and the confirmation on the final location of the components. On the other hand, there is software already making choices for us in creative contexts [19], AI creating content based on simple rules of competition on the internet [20], AI trading in the stock-market [21], etc.

While hardware is complex in nature to the point that it is not yet auto-generative, software and the abstraction that it derives from — algorithms — can be produced by software. The level of delegation we have in software cannot be compared with almost anything else before in history when measured from the perspective of scale and responsibility. Airplanes, carrying hundreds of passengers on board, are almost fully piloted by their on-board computer, car breaks are enhanced with algorithms that learn to understand the roads and control the brakes to avoid accidents... In the history of democracy (understood as the power of the many [22]), we have witnessed how people delegate power in other people that are somehow better equipped to perform certain tasks in the name of others. E.g. politicians represent their voters and should operate under the premise of doing the best for the many. There are mechanisms to help monitor the proper functioning of democracy: separation of powers, freedom of the press, labor unions, elections, or freedom of speech, just to mention a few. In the world of computing we haven't still created such mechanisms of control to rule the way our AI will behave. How can we ensure that a new AI commanding a self-driving car is behaving? Is there an international body such as IEEE creating the standards for how to build the certifications of these new artifacts born from self learning devices? Are we ready to create new labor laws that contemplate the interaction between this new generation of workers and humans? There are too many open questions that we haven't answered yet, furthermore, many of the answers rely in the interaction between corporations — that generate a lot of the know-how in the field — and governments.

However, regulatory efforts will be put in place at some point, since this is how our socio-economic system works. Once there is a potential point of conflict, society builds a new failsafe switch to try to control the situation. There are examples in history that range from the creation of laws to stop unjust cases of happening, to the evolution of our political systems to be more humane and up-to-date with our understanding of the world. It is a matter of time until new standards and regulations start policing our new AI-centric reality. But it that is going to happen, where is the risk then?

### Risks
We are immersed in an economic system — capitalism — that needs of the exchange of amounts of a scarceful resource — money — to continue to exist. The arrival of automation and AI brings with it a renovation of the workforce in an attempt to optimize the production of goods and services. Some authors see this, the removal of humans from traditional positions in the labor market, as an opportunity for creating a new type of labor based on micro-exchanges of data for money [23]. If what companies want is our data to create portfolios of aggregated information to sell marketing through, we could be paid for the sole purpose of feeding the AI algorithms with data [24]. While these prospects might make sense, they fail to realize — as Rouvroy mentions in her 2013 lecture on governmentality [2]— that algorithms are interested in data we are not interested in. Algorithms are fed with data that is not relevant to us, it is our data garbage that feeds them; but once aggregated and post-processed, it gains a new dimension that makes it worth as part of a deeper analysis. It is as if algorithms had the capability of recycling our left over data making it into information once more. This challenges the authors that believe we could work into feeding algorithms with data. The production of data is embodied, some of it comes from our daily interactions with others, some of it is generated by our self-quantification devices, some of it is traces left when making economic exchanges with the always-traceable-and-ubiquitous digital money. It is worth asking oneself whether it makes sense to work towards building a future where humans will work in data farms feeding self-thinking machines in a sorts of symbiotic relationship. It is hard to understand how a symbiosis with algorithms could work. It is much easier to imagine a parasitic relationship where algorithms extract the valuable from us by forcing us to abandon what is relevant to focus in making what they need.

But this raises yet another question, since algorithms are building their own categories and run their own judgement, how are we supposed to know what is good for them to further develop their judgement? From a different perspective, if the algorithms are interested in something that is inherently uninteresting for us, will that aspect change just because of the machine needing that data? The moment there is an economic incentive, will that kind of data cease to be irrelevant to us? Wouldn’t it become “just a job” and therefore be seen as an obligation not conducting our desires and instead imposing a lifestyle?

Given the relevance that AI is taking at economic and political level, if we fail to figure out an incentives-based mechanism to train AI, as mentioned above, we might have to make it mandatory — by the call to a communal process or similar mechanism — in order to achieve technological sovereignty. The question here transforms then: is it really necessary to reach a certain degree of algorithmic sovereignty? Wouldn’t we have to sacrifice too much of what makes us who and what we are? From a philosophical point of view we should also ask ourselves if feeding a machine to feed our lives with more recommendations and more marketing is a life worth living. We should discuss whether this way of understanding algorithmic sovereignty is of a real value to us as a collective and to each one of us as individuals.

### Governmentality and closing analysis
This term, coined by Foucault, refers to the mechanisms applied by the state to govern its citizens, but also to let them govern themselves given some constraints. If we start to rely on algorithms that are not regulated by humans, but that learn to create their own ad-hoc systems of judgement, how is that going to play along with the idea of technological sovereignty? It is for this reason that I consider algorithmic sovereignty very different from the technological one. It is built from another assumption. While technological sovereignty has the value of showing the world the ability of a group to be independent and self-sufficient, the algorithmic sovereignty moves in the dimension that separates humans and machines. It refers to a deeper conflict than human competition against others. Algorithmic sovereignty is about marking a red line on how far we will delegate on machines.

But if we are letting things go at so many different levels, I assume this is mainly to allow our society to continue to evolve, where are we going to keep our power to decide, or — formulating this question differently — are we even interested in keeping in control of a part of the process of making moral decisions? It is my intention — through the final version of this text — to prove that we are willing to do so at different levels: from the individual one, to the nation one, passing by all sorts of trans-border kind of communities. The mechanism that we will choose in order to keep control is what I like to call algorithmic sovereignty, or the ability to exercise power through algorithms, the main abstraction within the humachine (human-machine) assemblage our society is turning into.

This text will argue that in order to reach the vision of a world where humachines will cooperate in ensuring the continuation of the species, there is a need for the governments to take control of the most relevant platforms, coordinate efforts in regulating the aspects about AI and computing in general, educate the general public about the goods and the bads of these technologies, and re-think economic models around computing and data in general.

## References

[1.] Dourish, Paul. (2016) Algorithms and their others: Algorithmic culture in context, Big Data & Society [link]
[2.] Rouvroy, Antoniette. (2013) Society of the Query #2 - Antoinette Rouvroy: Algorithmic Governmentality and the End(s) of Critique, Vimeo [link]
[3.] Mantelero, Alessandro. (2016) Personal data for decisional purposes in the age of analytics: From an individual to a collective dimension of data protection, Computer Law and Security Review [link]
[4.] Johnson, Deborah G. and Miller, Keith W.. (2008) Un-making artificial moral agents, Ethics and Information Technology
[5.] Cuartielles, David. (2018) Platform Design, Malmo University
[6.] Mikton, John. (2015) The Internet of Things: ethics of our connectivity, Unknown source
[7.] Bennett, Jane. (2005) The agency of assemblages and the North American blackout, Public Culture
[8.] Hayles, N. K.. (2009) RFID: Human Agency and Meaning in Information-Intensive Environments, Theory, Culture & Society
[9.] Adam, Alison. (2005) Delegating and distributing morality: Can we inscribe privacy protection in a machine?, Ethics and Information Technology
[10.] Akrich, Madeleine. (1992) The de-scription of technical objects, Shaping technologybuilding society [link]
[11.] Feenberg, Andrew. (2010) Democratic Rationalization: Technology, Power, and Freedom, Unknown source [link]
[12.] Haraway, Donna J.. (1991) Simians, Cyborgs, and Women: The Reinvention of Nature., Unknown source [link]
[13.] Finley, Klint. (2017) Can Apple's iPhone X Beat Facial Recognition's Bias Problem? | WIRED, Unknown source [link]
[14.] Algorithmic Justice League. (2017) AJL - ALGORITHMIC JUSTICE LEAGUE, Unknown source [link]
[15.] Padilla, Margarita and Hache, Alex and Cadon, Benj.... (2017) Technological Sovereignty, Vol. 2, Unknown source [link]
[16.] Maurer, Tim and Morgus, Robert and Skierka, Isabel.... (2015) Technological Sovereignty: Missing the Point?, Unknown source
[17.] Vázquez, Daniel and Barandiaran, Xabier E. a.... (2015) Buen conocer/FLOK Society: modelos sostenibles y políticas públicas para una economía social del conocimiento común y abierto en Ecuador, CIESPAL [link]
[18.] Tapia, Andrea H. and Maldonado, Edgar. (2009) An ICT Skills Cascade: Government-Mandated Open Source Policy as a Potential Driver for ICT Skills Transfer, Information Technologies and International Development
[19.] Xing, Jun and Wei, Li-yi and Shiratori, Takaaki an.... (2015) Autocomplete Hand-drawn Animations, ACM Transactions on Graphics
[20.] Bridle, James. (2017) Something is wrong on the internet, Medium [link]
[21.] Cox, Jeff. (2017) A new robot-powered ETF AEIQ is beating the stock market, Website [link]
[22.] Lane, Melissa. (2014) Greek and Roman Political Ideas, Penguin Books
[23.] Brody, Paul and Pureswaran, Veena. (2015) Device democracy: Saving the future of the Internet of Things IBM, IBM Global Business Services Executive Report [link]
[24.] Arrieta Ibarra, Imanol and Goff, Leonard and Jimen.... (2018) Should We Treat Data as Labor?, American Economic Review, Papers and Proceedings
